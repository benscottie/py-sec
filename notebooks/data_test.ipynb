{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from sec_edgar_downloader import Downloader\n",
    "import glob\n",
    "import shutil\n",
    "import re\n",
    "import datefinder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SEC Downloader\n",
    "dl = Downloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Most Recent 10-K Filing for Apple\n",
    "company = 'GOOG'\n",
    "before_yr = 2021\n",
    "after_yr = 2000\n",
    "# dl.get('10-K', company, amount=1)\n",
    "\n",
    "# Get all 8-K filings for Apple after January 1, 2017 and before March 25, 2017\n",
    "# Note: after and before strings must be in the form \"YYYY-MM-DD\"\n",
    "dl.get(\"10-K\", company, after=f'{after_yr}-01-01', before=f'{before_yr}-01-21')\n",
    "\n",
    "# Get all 10-K filings for Apple\n",
    "# dl.get(\"10-K\", \"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify File Path\n",
    "company = 'MSFT'\n",
    "file = glob.glob(f\"sec-edgar-filings/{company}/10-K/**/*.html\", recursive = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 10-K HTML\n",
    "def load_html(fpath):\n",
    "    with open(fpath, 'r') as f:\n",
    "        return f.read()\n",
    "filing = load_html(file[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BS Object\n",
    "soup = BeautifulSoup(filing, 'html.parser')\n",
    "# Get Text Sections\n",
    "txt = [s.get_text().lower().strip() for s in soup.find_all('font')]\n",
    "txt = [s.get_text().lower().strip() for s in soup.find_all('span')] if not txt else txt\n",
    "txt = [s.replace('\\xa0', ' ').strip() for s in txt]\n",
    "txt = [re.sub('\\n', '', s) for s in txt]\n",
    "# Get Text Sections for Item 7\n",
    "idx_start = [i for i,s in enumerate(txt) if 'item 7.' in s]\n",
    "idx_end = [i for i,s in enumerate(txt) if 'item 7a.' in s]\n",
    "idx_item = np.argmax([e-s for e,s in zip(idx_end,idx_start)])\n",
    "items = txt[idx_start[idx_item]:idx_end[idx_item]]\n",
    "# Clean Text Sections\n",
    "items = [s for s in items if '10-k' not in s]\n",
    "items = list(filter(None, items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse & Clean Sections for Item 7\n",
    "def get_sections(items: list):\n",
    "    sections = []\n",
    "    txt = []\n",
    "    for i, item in enumerate(items):\n",
    "        if item.endswith('.'):\n",
    "            txt.append(item)\n",
    "        elif any(s.isalpha() for s in item)==True:\n",
    "            txt.append(item)\n",
    "        elif (item.isnumeric()) & (len(item)==4):\n",
    "            txt.append(item)\n",
    "    \n",
    "        if i < (len(items)-1):\n",
    "            if (items[i+1][0].isalpha()) & ('.' not in items[i+1]) & (txt[-1].endswith('.')):\n",
    "                sections.append(' '.join(txt))\n",
    "                txt = []\n",
    "    sections = [s for s in sections if s != 'item 7.']\n",
    "    return [' '.join(s.split()) for s in sections]\n",
    "\n",
    "sections = get_sections(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Full Text Split By Paragraph Indicators\n",
    "split_txt = '\\n\\n'.join(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine Item 7\n",
    "print(f'Length of Item: {len(sections)} Sections')\n",
    "avg_len = np.mean([len(s.split()) for s in sections])\n",
    "print(f'Average Section Length: {avg_len:.2f} Tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Date\n",
    "def get_date(txt: str):\n",
    "    date = txt.split('fiscal year ended')[1].split()[0:3]\n",
    "    date[2] = re.sub('\\D', '', date[2])\n",
    "    return ' '.join(date).capitalize()\n",
    "\n",
    "full_txt = soup.get_text().lower()\n",
    "date = get_date(full_txt)\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Downloaded Directory\n",
    "shutil.rmtree('sec-edgar-filings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-fruit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sec",
   "language": "python",
   "name": "sec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
